import pandas as pd
from django.core.exceptions import ValidationError

from core.models import AdultSocialCare, Contact, Housing, Person, Police, School

"""
These are fields that won't be used in CSV files, including foreign keys.
Ideally, this would be autogenerated as well, but not sure how to do it.
"""
UNNEEDED_FIELDS = ["other", "other_fields", "person", "service", "id", "contact"]


def get_fields_of_type(model, data_type):
    """
    Returns a list of fields from a given model that match a given data type
    :param model: The model to look at
    :param data_type: The data type we're looking for (e.g. DateField, etc)
    :return: A list of field names in a human-readable format
    """
    type_fields = []
    for field in model._meta.local_fields:
        if data_type in str(field.db_type):
            type_fields.append(field.name.replace("_", " ").title())
    return type_fields


def generate_model_field_list(model):
    """
    Generates a list of expected column names to be found in a given
    CSV based on the models. We don't want to maintain two separate
    lists of fields after all. Best to automate wherever possible
    :param model: The model to generate a field list from
    :return: A list of fields in an expected (case-sensitive) format
    """
    return [
        f.name.replace("_", " ").title()
        for f in model._meta.local_fields
        if f.name not in UNNEEDED_FIELDS
    ]


CONTACT_FIELDS = generate_model_field_list(Contact)
PERSON_FIELDS = generate_model_field_list(Person)
ADSC_FIELDS = generate_model_field_list(AdultSocialCare) + [
    "Contact {}".format(j) for j in CONTACT_FIELDS
]
SCHOOL_FIELDS = generate_model_field_list(School)
POLICE_FIELDS = generate_model_field_list(Police)
HOUSING_FIELDS = generate_model_field_list(Housing)

"""Each domain will have a key or set of key fields that will uniquely identify it."""
DOMAINS = {
    "Housing": {"Key": ["housing_association"], "Fields": HOUSING_FIELDS},
    "Police": {"Key": ["police_area"], "Fields": POLICE_FIELDS},
    "School": {"Key": ["school_name"], "Fields": SCHOOL_FIELDS},
    "ADSC": {"Key": ["local_authority_organisation"], "Fields": ADSC_FIELDS},
}


def validate_domain(domain_type, df):
    """
    Controlling function for validation. Branches based on the domain specified
    :param domain_type: Housing, Police, etc.
    :param df: The data frame we're validating
    :return: The dataframe with set data types along with a truthy value of if the
    validation was successful or not
    """
    if domain_type == "Housing":
        model = Housing
    elif domain_type == "Person":
        model = Person
    elif domain_type == "ADSC":
        model = AdultSocialCare
    elif domain_type == "School":
        model = School
    elif domain_type == "Police":
        model = Police
    else:
        df, False
    df, result = validate_model(df, model)
    return df, result


def check_empty_columns(df):
    """
    We need to check to see if key columns have empty values or not and flag that
    this will cause problems
    :param df: The dataframe, loaded from CSV likely
    :return: True/False depending on if there were empty values found
    """
    errors = 0
    for col in df.columns:
        miss = df[col].isnull().sum()
        if miss > 0:
            print("{} has {} missing value(s)".format(col, miss))
            errors += 1
    if errors > 0:
        return False
    return True


def check_for_blank_data(df):
    """
    Controlling function to detect all the empty or blank data that could cause problems
    :param df: The data frame, likely loaded from CSV
    """
    if df.empty:
        msg = "File appears to be empty. Please check the file and try again."
        raise ValidationError("{}".format(msg), status="invalid")

    if not check_empty_columns(df):
        msg = "File contains empty values. Please check the file try again"
        raise ValidationError("{}".format(msg), status="invalid")


def validate_person(df):
    """
    This validates the expected data types of the fields
    (e.g. Expected data formats, name restrictions, etc)
    :param df: The dataframe (likely loaded from CSV)
    :return: A dataframe with correctly set data types
    along with a truthy value based on if it was
    successful or not
    """
    try:
        df["Date Of Birth"] = pd.to_datetime(df["Date Of Birth"], format="%Y-%m-%d")
    except ValueError as err:
        print("Date of Birth field not in expected format: {}".format(err))
        return df, False
    return df, True


def validate_model(df, model):
    """
    This validates the expected data types of generic fields such
    as dates (e.g. Expected data formats, name restrictions, etc)
    :param df: The dataframe (likely loaded from CSV)
    :param model: Which model we're matching against
    :return: A dataframe with correctly set data types along
    with a truthy value based on if it was successful or not
    """

    # Date Fields are typically formatted the same way throughout.
    date_fields = get_fields_of_type(model, "DateField")

    for f in date_fields:
        try:
            df[f] = pd.to_datetime(df[f], format="%Y-%m-%d")
        except ValueError as err:
            print("{} field not in expected format: {}".format(f, err))
            return df, False
    return df, True
